---
categories: []
date: "2019-01-22T05:14:17+01:00"
authors: ["__McGuinness, LA__", "Warren‐Gash, C", "Moorhouse, LR", "Thomas, SL"]
draft: false
featured: true
image:
  caption: ""
  focal_point: ""
tags: ["Dementia", "Systematic review"]
title: The validity of dementia diagnoses in routinely collected electronic health records in the United Kingdom; a systematic review
publication: Pharmacoepidemiology & Drug Safety *28*:244– 255
abstract: "Purpose: The purpose of the study is to assess the validity of codes or algorithms used to identify dementia in UK electronic health record (EHR) primary care and hospitalisation databases.
<br>
<br>
Methods: Relevant studies were identified by searching the MEDLINE/EMBASE databases from inception to June 2018, hand‐searching reference lists, and consulting experts. The search strategy included synonyms for “Dementia”, “Europe”, and “EHR”. Studies were included if they validated dementia diagnoses in UK primary care or hospitalisation databases, irrespective of validation method used. The Quality Assessment for Diagnostic Accuracy Studies‐2 (QUADAS‐2) tool was used to assess risk of bias.
<br>
<br>
Results: From 1469 unique records, 14 relevant studies were included. Thirteen validated individual diagnoses against a reference standard, reporting high estimates of validity. Most reported only the positive predictive value (PPV), with estimates ranging between 0.09 and 1.0 and 0.62 and 0.85 in primary care and hospitalisation databases, respectively. One study performed a rate comparison, indicating good generalisability of dementia diagnoses in The Health Improvement Network (THIN) database to the UK population. Studies were of low methodological quality. As studies were not comparable, no summary validity estimates were produced.
<br>
<br>
Conclusion: While heterogenous across studies, reported validity estimates were generally high. However, the credibility of these estimates is limited by the methodological quality of studies, primarily resulting from insufficient blinding of researchers interpreting the reference test. Inadequate reporting, particularly of the specific codes validated, hindered comparison of estimates across studies. Future validation studies should make use of more robust reference tests, follow established reporting guidelines, and calculate all measures of validity."
doi: "10.1002/pds.4669"
---
